---
title: "Medindo Cobertura de Dossel a partir de imagens no R"
subtitle: "Explorando o pacote `{coveR}`"
date: "2023-06-21"
categories: [coveR, dossel, ecologia, pt-br, R, tags]
image: "https://gitlab.com/fchianucci/coveR/-/raw/master/inst/extdata/coveR-logo_HR.png"
draft: false
---

## Propósito

Surgiu uma demanda no laboratório, em que precisarei tirar medidas de cobertura de dossel de cada um dos *pitfall-traps* que estão instalados em campo.

Para adiantar, resolvi estudar e criar uma rotina para este propósito.

Abaixo explico brevemente cada um dos passos para sua realização.

```{r}
#| include: false

# set knitr options
knitr::opts_chunk$set(warning = FALSE, message = FALSE,
                      knitr.table.format = "html")

# set scientific notation to be displayed as numbers
options(scipen = 999)

# set locale to brazilian portuguese
Sys.setlocale(category = "LC_TIME", locale = "pt_BR.UTF-8")
```


## 1. Pacotes utilizados na sessão

Após pesquisar bastante, encontrei o pacote `{coveR}`, que foi escrito pelo *Francesco Chianucci*. Você pode ter mais informações no seu artigo de lançamento: [veja aqui](https://link.springer.com/article/10.1007/s00468-022-02338-5).

- Para que o `{coveR}` possa funcionar, são necessários os pacotes `{EBImage}` e `{exiftoolr}`, ver abaixo:

```{r}
#| eval: false
# Repositório BiocManager:
install.packages("BiocManager")

# Pacote {EBImage}
BiocManager::install("EBImage")

# Pacote {exiftoolr} + instalação
devtools::install_github("JoshOBrien/exiftoolr")
exiftoolr::install_exiftool()

# Pacote {coveR}
devtools::install_git("https://gitlab.com/fchianucci/coveR")
```
> Eu penei um pouco para instalar tudo com sucesso, mas nada que algumas horas de briga com o Linux não resolvam =)


```{r}
library(coveR)      # imagens de cobertura
library(cowplot)    # organizar plots
library(here)       # localização de arquivos
library(kableExtra) # tabelas
library(knitr)      # tabelas/imagens
library(patchwork)  # organizar plots
library(tidyverse)  # manipulação de dados
```



---

## 2. Dados iniciais


### 2.1. Criar o objeto principal

- Criando objeto `image`

```{r}
image <- here("posts/007-coveR/pics/pt03_ang.png")
```

```{r}
#| fig-cap: "Imagem gerada a partir de um celular com lente grande angular no Ponto 03."
#| fig-height: 100
#| fig-align: left
#| echo: false
knitr::include_graphics(image)
```


- O canal azul é preferido porque permite um maior contraste entre os pixels do céu e do dossel
- Isso é ilustrado a seguir:

```{r}
#| fig-cap: "Imagem original e suas respectivas bandas RGB (red, green e blue)"
#| fig-align: left
#| echo: false

p1 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt03_ang.png"))
p2 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt03_ang_mods/pt03_ang_red.png"))
p3 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt03_ang_mods/pt03_ang_green.png"))
p4 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt03_ang_mods/pt03_ang_blue.png"))

plot_grid(p1, p2, p3, p4,
          ncol = 2, 
          nrow = 2,
          labels = c("Original", "Red", "Green", "Blue"),
          label_colour = "red",
          label_x = -0.01,
          label_y = 0.2)
```


### 2.2. Selecionar o canal azul

- Selecionar o canal azul
- Criando objeto `img_blue`
- Função `open_blue()` importa a imagem transformando em um raster de canal único (azul)

```{r}
img_blue <- open_blue(image, which.blue = 3, exif = FALSE, crop = NULL)
```

```{r}
#| fig-cap: "Imagem raster feita a partir de uma banda azul."
#| fig-align: left
#| echo: false
sp::plot(img_blue)
```


### 2.3. Classificar os pixels e criar uma imagem binária

- Imagem binária onde céu (*1*) e dossel (*0*)
- A função `thd_blue()` recebe a imagem rasterizada azul e transforma em binária
- Utiliza a função `auto_thresh()` do pacote `{autothresholdr}` para definir o thresholding (limites) da imagem 
- O padrão é o método "*Minimum*", mas existem 17 métodos diferentes que podem ser testados (<https://imagej.net/plugins/auto-threshold>)
- Criando objetos `img_lim_min` (médoto "*Minimum*") e `img_lim_def` (método "*Default*")

```{r}
#| fig-cap: 'Imagem binária feita com o método "Minimum".'
#| fig-align: left
img_lim_min <- thd_blue(img_blue, method = "Minimum", display = TRUE)
```

```{r}
#| fig-cap: 'Imagem binária feita com o método "Default".'
#| fig-align: left
img_lim_def <- thd_blue(img_blue, method = "Default", display = TRUE)
```


### 2.4. Segmentar e nomear as lacunas

- Retornar os atributos do dossel requer uma classificação dos pixels (os valores *1* no raster binário)
    - largos: lacunas entre o dossel
    - pequenos: lacunas dentro do dossel
- A função `label_gaps()` usa a função `bwlabel()` do pacote `{EBImage}` para atribuir um valor numérico para cada lacuna distinta

```{r}
img_min_gaps <- label_gaps(img_lim_min)
```

```{r}
#| fig-cap: "Minimum"
#| echo: false
#| fig-align: left
sp::plot(img_min_gaps)
```

```{r}
img_def_gaps <- label_gaps(img_lim_def)
```

```{r}
#| fig-cap: "Default"
#| echo: false
#| fig-align: left
sp::plot(img_def_gaps)
```


### 2.5. Classificar lacunas baseadas no tamanho

Existem basicamente dois métodos para classificar as lacunas a depender do seus tamanhos.

- [Macfarlane et al., 2007](https://doi.org/10.1016/j.agrformet.2007.05.001)
    - Considera lacunas grandes aquelas com 1,3% da área da imagem.
- [Alivernini et al., 2018](https://doi.org/10.1007/s00468-018-1666-3)
    - Se baseia na distribuição estatística do tamanho das lacunas dentro da imagem.
    - Lacunas grandes são consideradas por $gL \ge \mu + \sqrt{{\sigma \over n}}$
    - Comparado ao método anterior, este é dependente da densidade do dossel, já que o limite das lacunas grandes vão variar a cada imagem.
    
Os métodos são implementados na função `extract_gap()`:

- Método "*Minimum*"
```{r}
# Macfarlane
df_min_mac <- extract_gap(img_min_gaps, gapmethod = "macfarlane")
kable(head(df_min_mac))

# Alivernini
df_min_ali <- extract_gap(img_min_gaps, gapmethod = "alivernini")
kable(head(df_min_ali))
```

- Método "*Default*"
```{r}
# Macfarlane
df_def_mac <- extract_gap(img_def_gaps, gapmethod = "macfarlane")
kable(head(df_min_mac))

# Alivernini
df_def_ali <- extract_gap(img_def_gaps, gapmethod = "alivernini")
kable(head(df_min_ali))
```


### 2.6. Recuperar atributos do dossel

- Função `get_canopy()` para estimar os atributos do dossel.
- Dentre eles:
    - **Fração das Lacunas** ($FL$) = fração dos pixels das lacunas (nomeados por *1* na imagem binária): $FL = {Tp \over Np}$, onde $Tp$ é o número de pixels de lacuna, $Np$ é o número total de pixels;
    - **Cobertura Foliar** ($CF$) = complemento da fração das lacunas: $CF = {1 - FL}$;
    - **Cobertura do Dossel** ($CD$) = complemento da fração das lacunas grandes: $CD = 1 - {Tp \over Np}$;
    - **Porosidade do Dossel** ($PD$) = fração das lacunas dentro dos dosséis: $PD = 1 - {CF \over CD}$

Os outros atributos podem ser verificados no artigo do [Chianucci et al.](https://link.springer.com/article/10.1007/s00468-022-02338-5).

- Método "*Minimum*"
```{r}
# Macfarlane
df2_min_mac <- get_canopy(df_min_mac)
kable(df2_min_mac)

# Alivernini
df2_min_ali <- get_canopy(df_min_ali)
kable(df2_min_ali)
```

- Método "*Default*"
```{r}
# Macfarlane
df2_def_mac <- get_canopy(df_def_mac)
kable(df2_def_mac)

# Alivernini
df2_def_ali <- get_canopy(df_def_ali)
kable(df2_def_ali)
```

### 2.7. Comparação

```{r}
#| echo: false
a <- rbind(df2_min_mac,
		   df2_min_ali,
		   df2_def_mac,
		   df2_def_ali) |> 
	cbind(methods = c("Minimum - Macfarlane",
				  "Minimum - Alivernini",
				  "Default - Macfarlane",
				  "Default - Alivernini"))
```


Para efeito de comparação, abaixo estão todos os bancos de dados produzidos:
```{r}
a |>
	select(methods,
		   CF = FC, 
		   CD = CC, 
		   PD = CP) |> 
	kable()
```


### 2.8. Programação funcional

Todo o processo anterior foi realizado para apenas uma imagem, abaixo está o processo para maiores volumes de dados.

Eu tirei fotos de 4 pontos diferentes, em 2 formatos diferentes de câmeras:

- **ang**: lente grande angular
- **normal**: lente normal

Abaixo, as imagens:
```{r}
#| echo: false
p1 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt03_ang.png"))
p2 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt03_normal.png"))
p3 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt10_ang.png"))
p4 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt10_normal.png"))
p5 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt12_ang.png"))
p6 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt12_normal.png"))
p7 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt20_ang.png"))
p8 <- ggdraw() + draw_image(here("posts/007-coveR/pics/pt20_normal.png"))
```

```{r}
#| fig-cap: "Do lado esquerdo, as imagens feitas com câmera grande angular, à direita, com câmera normal. Pontos: 03, 10, 12, e 20"
#| echo: false
plot_grid(p1, p2, p3, p4, p5, p6, p7, p8,
          ncol = 2, 
          nrow = 4,
          label_x = -0.01,
          label_y = 0.2)
```


O método utilizado foi o *Minimum*, e o método de medição de lacunas foi o *Macfarlane*.

```{r}
images <- dir(path = here("posts/007-coveR/pics"), pattern = "*.png", full.names = TRUE)

images |> 
    purrr::map(coveR, method = "Minimum", gapmethod = "macfarlane", exif = FALSE) |> 
    dplyr::bind_rows() |> 
	kable()
```


---

## 3. Resumo

Neste post, mostrei como:

- Fazer upload de imagens para o R;
- Rasterizar imagens;
- Transformar imagens rasterizadas para um formato binário;
- Transformar e classificar lacunas;
- Recuperar atributos de dossel através do pixelamento de imagens;
- Fazer o processo em lotes (batch).

Qualquer dúvida, basta entrar em contato ;)


---

## 4. Referências

Chianucci et al. 2022. coveR: an R package for processing digital cover photography images to retrieve forest canopy attributes. **Trees**, 1-10.

- Link: <https://link.springer.com/article/10.1007/s00468-022-02338-5>
- GitLab: <https://gitlab.com/fchianucci/coveR>

Alivernini, A., Fares, S., Ferrara, C. *et al.* 2018. An objective image analysis method for estimation of canopy attributes from digital cover photography. **Trees** 32, 713–723. 

Macfarlane, Craig; Grigg, Andrew; Crystelle Evangelista. 2007. Estimating forest leaf area using cover and fullframe fisheye photography: Thinking inside the circle. **Agricultural and Forest Meteorology** 146, 1–2: 1-12.



R.